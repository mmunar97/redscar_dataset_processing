{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZ_9YMQZj-6V"
   },
   "source": [
    "# Wound segmentation using U-Net\n",
    "\n",
    "This notebook contains all the code necessary to train the U-Net to segment wounds in the Redscar Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g4SSovO3EcTi"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from numpy.random import seed\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas\n",
    "import re\n",
    "import skimage\n",
    "import skimage.color\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "# This is a custom library that includes the different architectures considered in this study.\n",
    "from cnn_architectures.architectures.models.unet.unet import UNet\n",
    "# To install it, you have to grab the 1.0 version uploaded on the GitHub repository. \n",
    "# Important: There are other versions of the library, but these architectures are implemented and trained with 1.0.\n",
    "# pip install git+https://github.com/mmunar97/cnn_architectures\n",
    "\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaration of global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REDSCAR_DATASET_PATH = r\"/home/marc/UIB_EXPERIMENTS/REDSCAR\"\n",
    "REDSCAR_ML_PATH = os.path.join(REDSCAR_DATASET_PATH, r\"SUBSETS/MACHINE_LEARNING_DATASET\")\n",
    "REDSCAR_ML_TRAIN_PATH = os.path.join(REDSCAR_ML_PATH, r\"train\")\n",
    "REDSCAR_ML_TEST_PATH  = os.path.join(REDSCAR_ML_PATH, r\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaration of a Keras generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wound_generator(img_path: str, gt_path: str, size, batch_size: int):\n",
    "    images = sorted(glob.glob(img_path))\n",
    "    masks = sorted(glob.glob(gt_path))\n",
    "\n",
    "    batch_img = []\n",
    "    batch_mask = []\n",
    "    idx = 0\n",
    "    while(True):\n",
    "        path_img = images[idx % len(images)]\n",
    "        path_mask = masks[idx % len(images)]\n",
    "    \n",
    "        img = cv2.imread(path_img, 1)        \n",
    "        mask = cv2.imread(path_mask, 0)\n",
    "        \n",
    "        img = skimage.transform.resize(img, (size[0], size[1], 3))\n",
    "        mask = cv2.resize(mask, size)\n",
    "        \n",
    "        mask = mask / 255\n",
    "\n",
    "        batch_img.append(img)\n",
    "        batch_mask.append(np.dstack((mask, mask)))\n",
    "        \n",
    "        if ((idx % batch_size - 1) == 0) and idx != 0:            \n",
    "            batch_img = np.array(batch_img)\n",
    "            batch_mask = np.array(batch_mask)\n",
    "            \n",
    "            yield batch_img, batch_mask\n",
    "            \n",
    "            batch_img = []\n",
    "            batch_mask = []\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in wound_generator(REDSCAR_ML_TRAIN_PATH+'/IMAGES/*.png', REDSCAR_ML_TRAIN_PATH+'/GT_WOUND_MASK/*.png', (512, 512), 5):\n",
    "    print(image.shape, mask.shape)\n",
    "    plt.imshow(image[1,:,:])\n",
    "    plt.show()\n",
    "    plt.imshow(mask[1,:,:])\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of metrics for the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend \n",
    "\n",
    "def dice(y_true, y_pred):\n",
    "    y_true_f = backend.flatten(y_true)\n",
    "    y_pred_f = backend.flatten(y_pred)\n",
    "    intersection = backend.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection+1 ) / (backend.sum(y_true_f) + backend.sum(y_pred_f)+1 )\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1-dice(y_true, y_pred)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='dice', factor=0.5,\n",
    "                                   patience=3,\n",
    "                                   verbose=1, mode='max', cooldown=2, min_lr=1e-7)\n",
    "\n",
    "early = EarlyStopping(monitor=\"dice\",\n",
    "                      mode=\"max\",\n",
    "                      patience=8) \n",
    "callbacks_list = [early, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of the different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net with 25 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialise the model by adjusting some parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## PARAMETERS ##################\n",
    "BATCH_SIZE = 5\n",
    "TOTAL_IMAGES = 275\n",
    "STEPS_PER_EPOCH = TOTAL_IMAGES // BATCH_SIZE \n",
    "EPOCHS = 25\n",
    "INPUT_SIZE = 512\n",
    "NUMBER_FILTERS = 64\n",
    "\n",
    "EXPERIMENT_PATH = r\"/home/marc/UIB_EXPERIMENTS/CNN_EXPERIMENTS/UNET/EXPERIMENT1\"\n",
    "################################################\n",
    "\n",
    "model1 = UNet(input_size=(INPUT_SIZE,INPUT_SIZE, 3), \n",
    "              out_channel=1, \n",
    "              batch_normalization=True)\n",
    "\n",
    "model1.build(n_filters=NUMBER_FILTERS, dilation_rate=1, layer_depth = 5, last_activation=\"sigmoid\")\n",
    "model1.compile(loss_func=dice_loss, metrics = [dice], learning_rate = 3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check that the network structure is as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed with the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.train(train_generator=wound_generator(REDSCAR_ML_TRAIN_PATH+'/IMAGES/*.png', REDSCAR_ML_TRAIN_PATH+'/GT_WOUND_MASK/*.png', (INPUT_SIZE, INPUT_SIZE), BATCH_SIZE), \n",
    "             val_generator=wound_generator(REDSCAR_ML_TEST_PATH+'/IMAGES/*.png', REDSCAR_ML_TEST_PATH+'/GT_WOUND_MASK/*.png', (INPUT_SIZE, INPUT_SIZE), BATCH_SIZE), \n",
    "             epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH, \n",
    "             check_point_path=None, validation_steps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the training is finished, we save the model for future predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.model.save_weights(EXPERIMENT_PATH+f'/unet1_epochs={EPOCHS}_lr=3e-5_res=0.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how the training has performed during the different periods, as well as the performance of that training on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model1.history\n",
    "\n",
    "plt.figure(figsize=(9,6), dpi= 100, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['dice'])\n",
    "plt.plot(history.history['val_dice'])\n",
    "plt.title('Dice evolution')\n",
    "plt.ylabel('dice')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "plt.savefig(EXPERIMENT_PATH+f'/unet1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net with 55 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialise the model by adjusting some parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## PARAMETERS ##################\n",
    "BATCH_SIZE = 5\n",
    "TOTAL_IMAGES = 275\n",
    "STEPS_PER_EPOCH = TOTAL_IMAGES // BATCH_SIZE \n",
    "EPOCHS = 55\n",
    "INPUT_SIZE = 512\n",
    "NUMBER_FILTERS = 64\n",
    "\n",
    "EXPERIMENT_PATH = r\"/home/marc/UIB_EXPERIMENTS/CNN_EXPERIMENTS/UNET/EXPERIMENT1\"\n",
    "################################################\n",
    "\n",
    "model2 = UNet(input_size=(INPUT_SIZE,INPUT_SIZE, 3), \n",
    "              out_channel=1, \n",
    "              batch_normalization=True)\n",
    "\n",
    "model2.build(n_filters=NUMBER_FILTERS, dilation_rate=1, layer_depth = 5, last_activation=\"sigmoid\")\n",
    "model2.compile(loss_func=dice_loss, metrics = [dice], learning_rate = 3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check that the network structure is as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed with the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.train(train_generator=wound_generator(REDSCAR_ML_TRAIN_PATH+'/IMAGES/*.png', REDSCAR_ML_TRAIN_PATH+'/GT_WOUND_MASK/*.png', (INPUT_SIZE, INPUT_SIZE), BATCH_SIZE), \n",
    "             val_generator=wound_generator(REDSCAR_ML_TEST_PATH+'/IMAGES/*.png', REDSCAR_ML_TEST_PATH+'/GT_WOUND_MASK/*.png', (INPUT_SIZE, INPUT_SIZE), BATCH_SIZE), \n",
    "             epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH, \n",
    "             check_point_path=None, validation_steps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the training is finished, we save the model for future predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.model.save_weights(EXPERIMENT_PATH+f'/unet2_epochs={EPOCHS}_lr=3e-5_res=0.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how the training has performed during the different periods, as well as the performance of that training on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model2.history\n",
    "\n",
    "plt.figure(figsize=(9,6), dpi= 100, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['dice'])\n",
    "plt.plot(history.history['val_dice'])\n",
    "plt.title('Dice evolution')\n",
    "plt.ylabel('dice')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "plt.savefig(EXPERIMENT_PATH+f'/unet2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net with 100 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialise the model by adjusting some parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## PARAMETERS ##################\n",
    "BATCH_SIZE = 5\n",
    "TOTAL_IMAGES = 275\n",
    "STEPS_PER_EPOCH = TOTAL_IMAGES // BATCH_SIZE \n",
    "EPOCHS = 100\n",
    "INPUT_SIZE = 512\n",
    "NUMBER_FILTERS = 64\n",
    "\n",
    "EXPERIMENT_PATH = r\"/home/marc/UIB_EXPERIMENTS/CNN_EXPERIMENTS/UNET/EXPERIMENT1\"\n",
    "################################################\n",
    "\n",
    "model3 = UNet(input_size=(INPUT_SIZE,INPUT_SIZE, 3), \n",
    "              out_channel=1, \n",
    "              batch_normalization=True)\n",
    "\n",
    "model3.build(n_filters=NUMBER_FILTERS, dilation_rate=1, layer_depth = 5, last_activation=\"sigmoid\")\n",
    "model3.compile(loss_func=dice_loss, metrics = [dice], learning_rate = 3e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check that the network structure is as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed with the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.train(train_generator=wound_generator(REDSCAR_ML_TRAIN_PATH+'/IMAGES/*.png', REDSCAR_ML_TRAIN_PATH+'/GT_WOUND_MASK/*.png', (INPUT_SIZE, INPUT_SIZE), BATCH_SIZE), \n",
    "             val_generator=wound_generator(REDSCAR_ML_TEST_PATH+'/IMAGES/*.png', REDSCAR_ML_TEST_PATH+'/GT_WOUND_MASK/*.png', (INPUT_SIZE, INPUT_SIZE), BATCH_SIZE), \n",
    "             epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH, \n",
    "             check_point_path=None, validation_steps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the training is finished, we save the model for future predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.model.save_weights(EXPERIMENT_PATH+f'/unet3_epochs={EPOCHS}_lr=3e-5_res=0.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how the training has performed during the different periods, as well as the performance of that training on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model3.history\n",
    "\n",
    "plt.figure(figsize=(9,6), dpi= 100, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['dice'])\n",
    "plt.plot(history.history['val_dice'])\n",
    "plt.title('Dice evolution')\n",
    "plt.ylabel('dice')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "plt.savefig(EXPERIMENT_PATH+f'/unet3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of models on the test set\n",
    "\n",
    "Once the different models have been trained with the train set, we proceed to evaluate them on the test set. First, we declare the following function that allows us to evaluate the whole test set on a certain trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_model(model: UNet, image: np.ndarray, binary_threshold: float):\n",
    "    resized_image_normalized = skimage.transform.resize(image, (model.input_size[0], model.input_size[1], 3))\n",
    "    prediction = model.model.predict(np.array([resized_image_normalized]))\n",
    "    raw_prediction = prediction[0][:, :, 0]\n",
    "    raw_prediction_resized = skimage.transform.resize(raw_prediction, (image.shape[0], image.shape[1]))\n",
    "    \n",
    "    prediction_mask_bool = raw_prediction_resized >= binary_threshold\n",
    "    prediction_mask_int = 255 * prediction_mask_bool\n",
    "    \n",
    "    colormask = image.copy()\n",
    "    colormask[:, :, 0][prediction_mask_bool] = 0\n",
    "    colormask[:, :, 1][prediction_mask_bool] = 255\n",
    "    colormask[:, :, 2][prediction_mask_bool] = 0\n",
    "        \n",
    "    return prediction_mask_bool, prediction_mask_int, colormask\n",
    "\n",
    "def compute_metrics(model: UNet, images_path: str, gt_path: str, binary_threshold: float, prediction_saving_path: str, measures_saving_path: str, measures_file_name: str):\n",
    "    \n",
    "    files = []\n",
    "    jaccard_values = []\n",
    "    \n",
    "    for file in listdir(images_path):\n",
    "        if isfile(join(images_path, file)):\n",
    "            \n",
    "            filename = file.replace(\".png\", \"\")\n",
    "            \n",
    "            gt_image = cv2.imread(gt_path+rf\"/{file}\", cv2.IMREAD_GRAYSCALE)\n",
    "            gt_mask = gt_image/255\n",
    "            gt_mask = gt_mask.astype(int)\n",
    "            \n",
    "            image = cv2.imread(images_path+rf\"/{file}\")\n",
    "            \n",
    "            prediction_mask_bool, prediction_mask_int, prediction_colormask = predict_from_model(model=model, \n",
    "                                                                                                 image=image, \n",
    "                                                                                                 binary_threshold=binary_threshold)\n",
    "            \n",
    "            cv2.imwrite(prediction_saving_path+rf\"/{filename}_colormask.png\", prediction_colormask)\n",
    "            cv2.imwrite(prediction_saving_path+rf\"/{filename}_mask.png\", prediction_mask_int)\n",
    "\n",
    "            jaccard_value = jaccard_score(gt_mask.flatten(), prediction_mask_bool.flatten())\n",
    "            files.append(file)\n",
    "            jaccard_values.append(round(jaccard_value, 6))\n",
    "    \n",
    "    data = pandas.DataFrame({\n",
    "        'IMAGES': files, 'JACCARD': jaccard_values\n",
    "    })\n",
    "    data.to_csv(measures_saving_path+rf'/{measures_file_name}.txt', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of U-Net trained with 25 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional. Uncomment the following lines if the model is already trained and you want to load it from disk.\n",
    "\n",
    "# EXPERIMENT_PATH = r\"/home/marc/UIB_EXPERIMENTS/CNN_EXPERIMENTS/UNET/EXPERIMENT1\"\n",
    "# model1_path = \"/home/marc/UIB_EXPERIMENTS/CNN_EXPERIMENTS/UNET/EXPERIMENT1/unet1_epochs=25_lr=3e-4_res=0.h5\"\n",
    "# model1 = UNet(input_size=(512,512, 3), \n",
    "#               out_channel=1, \n",
    "#               batch_normalization=True)\n",
    "\n",
    "# model1.build(n_filters=64, dilation_rate=1, layer_depth = 5, last_activation=\"sigmoid\")\n",
    "# model1.load_weight(model1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics(model=model1, images_path=REDSCAR_ML_TRAIN_PATH+'/IMAGES', gt_path=REDSCAR_ML_TRAIN_PATH+'/GT_WOUND_MASK', binary_threshold=0.5, \n",
    "                prediction_saving_path=EXPERIMENT_PATH+'/unet1_evaluation/train', \n",
    "                measures_saving_path=EXPERIMENT_PATH+'/unet1_evaluation', \n",
    "                measures_file_name='train')\n",
    "\n",
    "compute_metrics(model=model1, images_path=REDSCAR_ML_TEST_PATH+'/IMAGES', gt_path=REDSCAR_ML_TEST_PATH+'/GT_WOUND_MASK', binary_threshold=0.5, \n",
    "                prediction_saving_path=EXPERIMENT_PATH+'/unet1_evaluation/test', \n",
    "                measures_saving_path=EXPERIMENT_PATH+'/unet1_evaluation', \n",
    "                measures_file_name='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of U-Net trained with 55 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional. Uncomment the following lines if the model is already trained and you want to load it from disk.\n",
    "\n",
    "# EXPERIMENT_PATH = r\"/home/marc/UIB_EXPERIMENTS/CNN_EXPERIMENTS/UNET/EXPERIMENT1\"\n",
    "# model2_path = \"/home/marc/UIB_EXPERIMENTS/CNN_EXPERIMENTS/UNET/EXPERIMENT1/unet2_epochs=55_lr=3e-4_res=0.h5\"\n",
    "# model2 = UNet(input_size=(512,512, 3), \n",
    "#               out_channel=1, \n",
    "#               batch_normalization=True)\n",
    "\n",
    "# model2.build(n_filters=64, dilation_rate=1, layer_depth = 5, last_activation=\"sigmoid\")\n",
    "# model2.load_weight(model2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "compute_metrics(model=model2, images_path=REDSCAR_ML_TRAIN_PATH+'/IMAGES', gt_path=REDSCAR_ML_TRAIN_PATH+'/GT_WOUND_MASK', binary_threshold=0.5, \n",
    "                prediction_saving_path=EXPERIMENT_PATH+'/unet2_evaluation/train', \n",
    "                measures_saving_path=EXPERIMENT_PATH+'/unet2_evaluation', \n",
    "                measures_file_name='train')\n",
    "\n",
    "compute_metrics(model=model2, images_path=REDSCAR_ML_TEST_PATH+'/IMAGES', gt_path=REDSCAR_ML_TEST_PATH+'/GT_WOUND_MASK', binary_threshold=0.5, \n",
    "                prediction_saving_path=EXPERIMENT_PATH+'/unet2_evaluation/test', \n",
    "                measures_saving_path=EXPERIMENT_PATH+'/unet2_evaluation', \n",
    "                measures_file_name='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of U-Net trained with 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional. Uncomment the following lines if the model is already trained and you want to load it from disk.\n",
    "\n",
    "# EXPERIMENT_PATH = r\"/home/marc/UIB_EXPERIMENTS/CNN_EXPERIMENTS/UNET/EXPERIMENT1\"\n",
    "# model3_path = \"/home/marc/UIB_EXPERIMENTS/CNN_EXPERIMENTS/UNET/EXPERIMENT1/unet3_epochs=100_lr=3e-4_res=0.h5\"\n",
    "# model3 = UNet(input_size=(512,512, 3), \n",
    "#               out_channel=1, \n",
    "#               batch_normalization=True)\n",
    "\n",
    "# model3.build(n_filters=64, dilation_rate=1, layer_depth = 5, last_activation=\"sigmoid\")\n",
    "# model3.load_weight(model3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics(model=model3, images_path=REDSCAR_ML_TRAIN_PATH+'/IMAGES', gt_path=REDSCAR_ML_TRAIN_PATH+'/GT_WOUND_MASK', binary_threshold=0.5, \n",
    "                prediction_saving_path=EXPERIMENT_PATH+'/unet3_evaluation/train', \n",
    "                measures_saving_path=EXPERIMENT_PATH+'/unet3_evaluation', \n",
    "                measures_file_name='train')\n",
    "\n",
    "compute_metrics(model=model3, images_path=REDSCAR_ML_TEST_PATH+'/IMAGES', gt_path=REDSCAR_ML_TEST_PATH+'/GT_WOUND_MASK', binary_threshold=0.5, \n",
    "                prediction_saving_path=EXPERIMENT_PATH+'/unet3_evaluation/test', \n",
    "                measures_saving_path=EXPERIMENT_PATH+'/unet3_evaluation', \n",
    "                measures_file_name='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "U-Net.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "redscar_experiments",
   "language": "python",
   "name": "redscar_experiments"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
